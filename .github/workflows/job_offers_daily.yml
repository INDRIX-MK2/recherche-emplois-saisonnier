name: job_offers_daily

on:
  workflow_dispatch:
    inputs:
      search_terms:
        description: "Mots-clés pour la recherche (ex: serveur logé, aide barman logé, vendanges logé)"
        type: string
        required: true
        default: "serveur logé, aide barman logé, runner logé, vendanges logé, ouvrier cave logé, aide caviste logé, employé polyvalent logé, cueilleur logé"

  schedule:
    # 09:00 Europe/Paris = 07:00 UTC (été) et 08:00 UTC (hiver)
    - cron: "0 7 * * *"
    - cron: "0 8 * * *"

jobs:
  crawl_and_send:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Paris
      OPENAI_MODEL: gpt-5-mini
      OPENAI_TEMPERATURE: "1"
      OPENAI_CHUNK_SIZE: "25"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install "httpx<0.28"
          pip install requests beautifulsoup4 lxml html5lib backoff "openai==1.51.0"

      - name: Guard 09:00 Europe/Paris (éviter les doublons)
        env:
          GITHUB_EVENT_NAME: ${{ github.event_name }}
        run: |
          NOW_HOUR="$(date +'%H')"
          if [ "$GITHUB_EVENT_NAME" = "schedule" ] && [ "$NOW_HOUR" != "09" ]; then
            echo "Skipping, current hour: $NOW_HOUR (target 09:00 Europe/Paris)"
            exit 0
          fi

      - name: Write sites.json
        run: |
          printf '%s\n' \
          '[' \
          '  "francetravail","indeed","hellowork","meteojob","adzuna","alljobs","linkedin","google_jobs","lesjeudis","leboncoin","manpower"' \
          ']' > sites.json
          cat sites.json

      - name: Write filters.json
        run: |
          printf '%s\n' \
          '{' \
          '  "must_have_housing": true,' \
          '  "min_duration_days": 7,' \
          '  "max_duration_days": 92,' \
          '  "allow_only_metropole": true,' \
          '  "exclude_corse": true,' \
          '  "exclude_domcom": true,' \
          '  "allowed_jobs": [' \
          '    "serveur","serveuse","runner","aide de salle","aide barman","commis de bar",' \
          '    "vendangeur","porteuse","porteur","trieur","ouvrier agricole polyvalent",' \
          '    "ouvrier de cave","aide caviste","employe polyvalent","employé polyvalent",' \
          '    "cueilleur","cueilleuse"' \
          '  ]' \
          '}' > filters.json
          cat filters.json

      - name: Write fetch_sites.py
        run: |
          printf '%s\n' \
          'import json, os, requests' \
          'SITES = json.load(open("sites.json","r",encoding="utf-8"))' \
          'TERMS = os.getenv("SEARCH_TERMS","").strip() or "${{ github.event.inputs.search_terms }}"' \
          'def q(s): return requests.utils.quote(s)' \
          'def results_indeed(t): return [{"source":"indeed","url":f"https://fr.indeed.com/jobs?q={q(t)}+log%C3%A9&l=France","title":"Indeed search: "+t}]' \
          'def results_hellowork(t): return [{"source":"hellowork","url":f"https://www.hellowork.com/fr-fr/emploi/recherche.html?k={q(t)}+logement","title":"HelloWork : "+t}]' \
          'def results_francetravail(t): return [{"source":"francetravail","url":f"https://candidat.francetravail.fr/offres/recherche?k={q(t)}&l=France","title":"France Travail : "+t}]' \
          'def results_simple(engine, t): return [{"source":engine,"url":f"https://www.google.com/search?q=site%3A{engine}.com+{q(t)}+log%C3%A9+France","title":engine+" via Google"}]' \
          'DISPATCH = {"indeed":results_indeed,"hellowork":results_hellowork,"francetravail":results_francetravail}' \
          'raw=[]' \
          'terms=[x.strip() for x in TERMS.split(",") if x.strip()] or ["serveur logé","aide barman logé","runner logé","vendanges logé","ouvrier cave logé","aide caviste logé","employé polyvalent logé","cueilleur logé"]' \
          'for site in SITES:' \
          '  for t in terms:' \
          '    fn=DISPATCH.get(site)' \
          '    raw.extend(fn(t) if fn else results_simple(site,t))' \
          'json.dump(raw, open("offers_raw.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print("Collected seeds:", len(raw))' \
          > fetch_sites.py
          python fetch_sites.py

      - name: Write filter_with_gpt.py
        run: |
          printf '%s\n' \
          'import json, os' \
          'import backoff, httpx' \
          'from openai import OpenAI' \
          'from openai import APIConnectionError, RateLimitError, APIStatusError, APITimeoutError' \
          '' \
          'MODEL = os.getenv("OPENAI_MODEL","gpt-5-mini")' \
          'TEMP = float(os.getenv("OPENAI_TEMPERATURE","1"))' \
          'CHUNK_SIZE = int(os.getenv("OPENAI_CHUNK_SIZE","25"))' \
          '' \
          'client = OpenAI(timeout=120.0, max_retries=2)' \
          '' \
          'offers = json.load(open("offers_raw.json","r",encoding="utf-8"))' \
          'filters = json.load(open("filters.json","r",encoding="utf-8"))' \
          '' \
          'sys_prompt = {"role":"system","content":"Tu filtres des offres. NE SUPPRIME RIEN. Pour chaque offre, ajoute un score (0-100) basé sur: 1) logement (priorité max), 2) lieu (France métropolitaine, sans Corse/DOM-COM), 3) durée (7-92 jours), 4) métier (dans la liste). Réponds en JSON strict {offers:[{...}]}. Court et structuré."}' \
          '' \
          '@backoff.on_exception(' \
          '  backoff.expo,' \
          '  (APIConnectionError, httpx.RemoteProtocolError, httpx.ConnectError, httpx.ReadTimeout, RateLimitError, APIStatusError, APITimeoutError),' \
          '  max_tries=6,' \
          '  jitter=backoff.full_jitter' \
          ')' \
          'def call_openai(payload):' \
          '  return client.chat.completions.create(' \
          '    model=MODEL,' \
          '    temperature=TEMP,' \
          '    response_format={"type":"json_object"},' \
          '    messages=[' \
          '      sys_prompt,' \
          '      {"role":"user","content": json.dumps(payload, ensure_ascii=False)}' \
          '    ]' \
          '  )' \
          '' \
          'def chunks(lst, n):' \
          '  for i in range(0, len(lst), n):' \
          '    yield lst[i:i+n]' \
          '' \
          'aggregated = []' \
          'for idx, part in enumerate(chunks(offers, CHUNK_SIZE), start=1):' \
          '  payload = {"filters": filters, "offers": part}' \
          '  resp = call_openai(payload)' \
          '  content = resp.choices[0].message.content' \
          '  try:' \
          '    data = json.loads(content)' \
          '    part_offers = data.get("offers", [])' \
          '  except Exception:' \
          '    part_offers = [{"title":"(parse error)","source":"gpt","url":"#","note":"Réponse non JSON","score":0}]' \
          '  aggregated.extend(part_offers)' \
          '  print(f"Chunk {idx}: +{len(part_offers)} items")' \
          '' \
          'out = {"offers": aggregated}' \
          'json.dump(out, open("offers_filtered.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print("Done. Total items:", len(aggregated))' \
          > filter_with_gpt.py

      - name: Run filtering (GPT-5 mini)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python filter_with_gpt.py

      - name: Write email_report.py
        run: |
          printf '%s\n' \
          'import os, smtplib, json, sys' \
          'from urllib.parse import urlparse, parse_qs' \
          'from email.mime.multipart import MIMEMultipart' \
          'from email.mime.text import MIMEText' \
          '' \
          'RECIPIENT = os.getenv("RECIPIENT_EMAIL")' \
          'SENDER = os.getenv("SENDER_EMAIL")' \
          'SMTP_HOST = os.getenv("SMTP_HOST")' \
          'SMTP_PORT = int(os.getenv("SMTP_PORT"))' \
          'SMTP_USER = os.getenv("SMTP_USER")' \
          'SMTP_PASS = os.getenv("SMTP_PASS")' \
          '' \
          '# Charge d abord filtered, sinon raw pour fallback' \
          'data = {}' \
          'for path in ("offers_filtered.json","offers_raw.json"):' \
          '    try:' \
          '        data = json.load(open(path,"r",encoding="utf-8"))' \
          '        break' \
          '    except Exception:' \
          '        continue' \
          'items = data.get("offers", []) if isinstance(data, dict) else data' \
          '' \
          'SRC_MAP = {' \
          '  "francetravail":"France Travail",' \
          '  "hellowork":"HelloWork",' \
          '  "indeed":"Indeed",' \
          '  "meteojob":"Meteojob",' \
          '  "adzuna":"Adzuna",' \
          '  "alljobs":"AllJobs",' \
          '  "linkedin":"LinkedIn",' \
          '  "google_jobs":"Google for Jobs",' \
          '  "lesjeudis":"Les Jeudis",' \
          '  "leboncoin":"Le Bon Coin",' \
          '  "manpower":"Manpower"' \
          '}' \
          '' \
          'def pretty_source(s):' \
          '    if not s: return "?"' \
          '    return SRC_MAP.get(s.strip().lower(), s.strip().title())' \
          '' \
          'def get_company(it):' \
          '    for k in ("company","employer","employer_name","entreprise","recruteur","societe","organisation"):' \
          '        v = it.get(k) if isinstance(it, dict) else None' \
          '        if isinstance(v, str) and v.strip(): return v.strip()' \
          '    return "—"' \
          '' \
          'def is_search_or_list(url):' \
          '    try:' \
          '        u = urlparse(url)' \
          '        host = (u.netloc or "").lower()' \
          '        path = (u.path or "").lower()' \
          '        if not host: return True' \
          '        if "google." in host: return True' \
          '        if "recherche" in path and "detail" not in path: return True' \
          '        if any(seg in path for seg in ["/jobs","/emploi/recherche","/search","/recherche","/offres"]): return True' \
          '        return False' \
          '    except Exception:' \
          '        return True' \
          '' \
          'def build_offer_link(it):' \
          '    src_raw = (it.get("source") or "").strip().lower()' \
          '    offer_url = (it.get("offer_url") or "").strip()' \
          '    url = (it.get("url") or "").strip()' \
          '    page_url = (it.get("page_url") or "").strip()' \
          '    oid = (it.get("offer_id") or "").strip()' \
          '    # 1) lien explicite' \
          '    if offer_url and not is_search_or_list(offer_url):' \
          '        return offer_url' \
          '    # 2) url deja direct' \
          '    if url and not is_search_or_list(url):' \
          '        return url' \
          '    # 3) reconstruction par source' \
          '    if src_raw == "francetravail" and oid:' \
          '        return "https://candidat.francetravail.fr/offres/recherche/detail/{0}".format(oid)' \
          '    # 4) indeed: si page_url contient param jk' \
          '    if page_url:' \
          '        try:' \
          '            u = urlparse(page_url)' \
          '            if "indeed." in (u.netloc or "").lower():' \
          '                jk = (parse_qs(u.query).get("jk") or [""])[0]' \
          '                if jk:' \
          '                    return "https://{0}/viewjob?jk={1}".format(u.netloc, jk)' \
          '        except Exception:' \
          '            pass' \
          '    # sinon: pas de lien d offre fiable' \
          '    return ""' \
          '' \
          'html = ["<h2>Offres saisonnières</h2>", "<ol>"]' \
          'for it in items[:200]:' \
          '    if not isinstance(it, dict):' \
          '        continue' \
          '    src = pretty_source(it.get("source","?"))' \
          '    title = (it.get("title") or "Offre").strip()' \
          '    comp = get_company(it)' \
          '    score = it.get("score","?")' \
          '    mail = (it.get("employer_email") or "").strip() or "—"' \
          '    link = build_offer_link(it)' \
          '    if link:' \
          '        lien_html = "<a href=&quot;{0}&quot;>Lien</a>".format(link)' \
          '    else:' \
          '        lien_html = "Lien indisponible"' \
          '    line = "{0}: {1} - {2} - Score: {3} - {4} - {5}"' \
          '    html.append("<li>" + line.format(src, title, comp, score, lien_html, mail) + "</li>")' \
          'html.append("</ol>")' \
          '' \
          'msg = MIMEMultipart("alternative")' \
          'msg["Subject"] = "Veille offres saisonnières"' \
          'msg["From"] = SENDER' \
          'msg["To"] = RECIPIENT' \
          'msg.attach(MIMEText("\\n".join(html), "html", "utf-8"))' \
          '' \
          'with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as s:' \
          '  s.starttls(); s.login(SMTP_USER, SMTP_PASS)' \
          '  s.sendmail(SMTP_USER, [x.strip() for x in RECIPIENT.split(",") if x.strip()], msg.as_string())' \
          'print("Email sent to", RECIPIENT)' \
          > email_report.py




      - name: Send email
        env:
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENTS }}
          SENDER_EMAIL: ${{ secrets.SMTP_FROM }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
        run: python email_report.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job_offers
          path: |
            sites.json
            filters.json
            offers_raw.json
            offers_filtered.json