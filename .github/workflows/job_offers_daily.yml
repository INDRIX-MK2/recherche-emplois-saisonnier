name: job_offers_daily

on:
  workflow_dispatch:
    inputs:
      search_terms:
        description: "Mots-clés pour la recherche (ex: serveur logé, aide barman logé, vendanges logé)"
        type: string
        required: true
        default: "serveur logé, aide barman logé, runner logé, vendanges logé, ouvrier cave logé, aide caviste logé, employé polyvalent logé, cueilleur logé"

  schedule:
    # 09:00 Europe/Paris = 07:00 UTC (été) et 08:00 UTC (hiver)
    - cron: "0 7 * * *"
    - cron: "0 8 * * *"

jobs:
  crawl_and_send:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Paris
      OPENAI_MODEL: gpt-5-mini
      OPENAI_TEMPERATURE: "1"
      OPENAI_CHUNK_SIZE: "25"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "httpx<0.28"
          pip install requests beautifulsoup4 lxml html5lib backoff "openai==1.51.0"

      - name: Guard 09:00 Europe/Paris (éviter les doublons)
        env:
          GITHUB_EVENT_NAME: ${{ github.event_name }}
        run: |
          NOW_HOUR="$(date +'%H')"
          if [ "$GITHUB_EVENT_NAME" = "schedule" ] && [ "$NOW_HOUR" != "09" ]; then
            echo "Skipping, current hour: $NOW_HOUR (target 09:00 Europe/Paris)"
            exit 0
          fi

      # ---- Config ----
      - name: Write sites.json
        run: |
          printf '%s\n' \
          '[' \
          '  "francetravail","indeed","hellowork","monster","jobijoba","meteojob","keljob","adzuna","alljobs","jora","jobted","linkedin","google_jobs","apec","cadremploi","wttj","lesjeudis","jobteaser","jobsthatsense","chooseyourboss","leboncoin","manpower","ouestjob"' \
          ']' > sites.json
          cat sites.json

      - name: Write filters.json
        run: |
          printf '%s\n' \
          '{' \
          '  "must_have_housing": true,' \
          '  "min_duration_days": 7,' \
          '  "max_duration_days": 92,' \
          '  "allow_only_metropole": true,' \
          '  "exclude_corse": true,' \
          '  "exclude_domcom": true,' \
          '  "allowed_jobs": [' \
          '    "serveur","serveuse","runner","aide de salle","aide barman","commis de bar",' \
          '    "vendangeur","porteuse","porteur","trieur","ouvrier agricole polyvalent",' \
          '    "ouvrier de cave","aide caviste","employe polyvalent","employé polyvalent",' \
          '    "cueilleur","cueilleuse"' \
          '  ]' \
          '}' > filters.json
          cat filters.json

      # ---- Étape 1: Collecte brute des liens de recherche ----
      - name: Write fetch_sites.py
        run: |
          printf '%s\n' \
          'import json, os, requests' \
          'SITES = json.load(open("sites.json","r",encoding="utf-8"))' \
          'TERMS = os.getenv("SEARCH_TERMS","").strip() or "${{ github.event.inputs.search_terms }}"' \
          'def q(s): return requests.utils.quote(s)' \
          '' \
          'def results_indeed(t): return [{"source":"indeed","url":f"https://fr.indeed.com/jobs?q={q(t)}&l=France","title":"Indeed search: "+t}]' \
          'def results_hellowork(t): return [{"source":"hellowork","url":f"https://www.hellowork.com/fr-fr/emploi/recherche.html?k={q(t)}&l=France","title":"HelloWork search: "+t}]' \
          'def results_monster(t): return [{"source":"monster","url":f"https://www.monster.fr/emploi/recherche/?q={q(t)}&where=France","title":"Monster search: "+t}]' \
          'def results_francetravail(t): return [{"source":"francetravail","url":f"https://candidat.francetravail.fr/offres/recherche?k={q(t)}&l=France","title":"France Travail search: "+t}]' \
          'def results_simple(engine, t): return [{"source":engine,"url":f"https://www.google.com/search?q=site%3A{engine}.com+{q(t)}+France","title":engine+" via Google"}]' \
          '' \
          'DISPATCH = {"indeed":results_indeed,"hellowork":results_hellowork,"monster":results_monster,"francetravail":results_francetravail}' \
          '' \
          'raw=[]' \
          'terms=[x.strip() for x in TERMS.split(",") if x.strip()] or ["serveur","aide barman","runner","vendanges","ouvrier cave","aide caviste","employé polyvalent","cueilleur"]' \
          'for site in SITES:' \
          '  for t in terms:' \
          '    fn = DISPATCH.get(site)' \
          '    raw.extend(fn(t) if fn else results_simple(site, t))' \
          '' \
          'json.dump(raw, open("offers_raw.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print("Collected seeds:", len(raw))' \
          > fetch_sites.py
          python fetch_sites.py

      # ---- Étape 2: GPT-5-mini enrichissement complet ----
      - name: Write filter_with_gpt.py
        run: |
          printf '%s\n' \
          'import json, os' \
          'import backoff, httpx' \
          'from openai import OpenAI' \
          'from openai import APIConnectionError, RateLimitError, APIStatusError, APITimeoutError' \
          '' \
          'MODEL = os.getenv("OPENAI_MODEL","gpt-5-mini")' \
          'TEMP = float(os.getenv("OPENAI_TEMPERATURE","1"))' \
          'CHUNK_SIZE = int(os.getenv("OPENAI_CHUNK_SIZE","25"))' \
          '' \
          'client = OpenAI(timeout=120.0, max_retries=2)' \
          '' \
          'offers = json.load(open("offers_raw.json","r",encoding="utf-8"))' \
          'filters = json.load(open("filters.json","r",encoding="utf-8"))' \
          '' \
          'sys_prompt = {"role":"system","content": """Tu recois des liens de recherche d offres saisonnieres.' \
          'Pour chaque lien, fais ceci:' \
          '1) Extraire toutes les annonces listees.' \
          '2) Pour chaque annonce, recuperer le titre, le lien direct, le numero d offre (id) s il est present, et l email de contact employeur s il existe.' \
          '3) Appliquer un score 0-100 base sur: logement disponible (priorite), localisation France metropolitaine (pas Corse ni DOM-COM), duree entre 7 et 92 jours, metiers autorises.' \
          'Retourner uniquement du JSON strict au format {offers:[{title,source,url,offer_id,employer_email,score,note}]}."""}' \
          '' \
          '@backoff.on_exception(' \
          '  backoff.expo,' \
          '  (APIConnectionError, httpx.RemoteProtocolError, httpx.ConnectError, httpx.ReadTimeout, RateLimitError, APIStatusError, APITimeoutError),' \
          '  max_tries=6,' \
          '  jitter=backoff.full_jitter' \
          ')' \
          'def call_openai(payload):' \
          '  return client.chat.completions.create(' \
          '    model=MODEL,' \
          '    temperature=TEMP,' \
          '    response_format={"type":"json_object"},' \
          '    messages=[' \
          '      sys_prompt,' \
          '      {"role":"user","content": json.dumps(payload, ensure_ascii=False)}' \
          '    ]' \
          '  )' \
          '' \
          'def chunks(lst, n):' \
          '  for i in range(0, len(lst), n):' \
          '    yield lst[i:i+n]' \
          '' \
          'aggregated = []' \
          'for idx, part in enumerate(chunks(offers, CHUNK_SIZE), start=1):' \
          '  payload = {"filters": filters, "offers": part}' \
          '  resp = call_openai(payload)' \
          '  content = resp.choices[0].message.content' \
          '  try:' \
          '    data = json.loads(content)' \
          '    part_offers = data.get("offers", [])' \
          '  except Exception:' \
          '    part_offers = [{"title":"(parse error)","source":"gpt","url":"#","note":"Reponse non JSON","score":0}]' \
          '  aggregated.extend(part_offers)' \
          '  print(f"Chunk {idx}: +{len(part_offers)} items")' \
          '' \
          'out = {"offers": aggregated}' \
          'json.dump(out, open("offers_filtered.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print("Done. Total items:", len(aggregated))' \
          > filter_with_gpt.py
          python filter_with_gpt.py
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      # ---- Étape 3: Email rapport enrichi ----
      - name: Write email_report.py
        run: |
          printf '%s\n' \
          'import os, smtplib, json' \
          'from email.mime.multipart import MIMEMultipart' \
          'from email.mime.text import MIMEText' \
          '' \
          'RECIPIENT = os.getenv("RECIPIENT_EMAIL")' \
          'SENDER = os.getenv("SENDER_EMAIL")' \
          'SMTP_HOST = os.getenv("SMTP_HOST")' \
          'SMTP_PORT = int(os.getenv("SMTP_PORT"))' \
          'SMTP_USER = os.getenv("SMTP_USER")' \
          'SMTP_PASS = os.getenv("SMTP_PASS")' \
          '' \
          'data = json.load(open("offers_filtered.json","r",encoding="utf-8"))' \
          '' \
          'html = ["<h2>Offres saisonnieres - Rapport</h2>", "<ol>"]' \
          'for item in data.get("offers", [])[:200]:' \
          '    title = item.get("title", "Offre")' \
          '    url = item.get("url", "#")' \
          '    score = item.get("score", "?")' \
          '    source = item.get("source", "?")' \
          '    note = item.get("note", "")' \
          '    oid = item.get("offer_id", "")' \
          '    mail = item.get("employer_email", "")' \
          '' \
          '    extra = []' \
          '    if oid: extra.append(f"ID: {oid}")' \
          '    if mail: extra.append(f"<span>Contact: <a href=\\"mailto:{mail}\\">{mail}</a></span>")' \
          '' \
          '    extra_html = " — ".join(extra)' \
          '    if extra_html: extra_html = " — " + extra_html' \
          '' \
          '    html.append(f"<li><b>{title}</b> - {source} - Score: {score}{extra_html} - <a href=\\"{url}\\">Lien</a> - {note}</li>")' \
          '' \
          'html.append("</ol>")' \
          '' \
          'msg = MIMEMultipart("alternative")' \
          'msg["Subject"] = "Veille offres saisonnieres enrichie (GPT-5-mini)"' \
          'msg["From"] = SENDER' \
          'msg["To"] = RECIPIENT' \
          'msg.attach(MIMEText("\\n".join(html), "html", "utf-8"))' \
          '' \
          'with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as s:' \
          '    s.starttls()' \
          '    s.login(SMTP_USER, SMTP_PASS)' \
          '    s.sendmail(SENDER, [x.strip() for x in RECIPIENT.split(",") if x.strip()], msg.as_string())' \
          'print("Email sent to", RECIPIENT)' \
          > email_report.py
          python email_report.py
        env:
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENTS }}
          SENDER_EMAIL: ${{ secrets.SMTP_FROM }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}

      # ---- Étape 4: Artifacts pour debug ----
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job_offers
          path: |
            sites.json
            filters.json
            offers_raw.json
            offers_filtered.json