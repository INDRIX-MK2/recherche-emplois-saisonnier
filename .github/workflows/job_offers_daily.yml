name: job_offers_daily

on:
  workflow_dispatch:
    inputs:
      search_terms:
        description: "Mots-clés prioritaires (ex: serveur logé, vendanges logé, aide barman, runner)"
        type: string
        required: true
        default: "serveur logé, aide barman logé, runner logé, vendanges logé, ouvrier cave logé, aide caviste logé, employé polyvalent logé, cueilleur logé"

  schedule:
    # GitHub Actions est en UTC. 09:00 Europe/Paris = 07:00 UTC (été) ou 08:00 UTC (hiver)
    - cron: "0 7 * * *"
    - cron: "0 8 * * *"

jobs:
  crawl_and_send:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Paris
      OPENAI_MODEL: gpt-4o-mini
      OPENAI_TEMPERATURE: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml html5lib openai==1.51.0

      - name: Guard 09:00 Europe/Paris (éviter les doublons)
        env:
          GITHUB_EVENT_NAME: ${{ github.event_name }}
        run: |
          NOW_HOUR="$(date +'%H')"
          if [ "$GITHUB_EVENT_NAME" = "schedule" ] && [ "$NOW_HOUR" != "09" ]; then
            echo "Skipping, current hour: $NOW_HOUR (waiting 09:00 Europe/Paris)"
            exit 0
          fi
    


      # ------------------------------
      # Fichier des sites à scanner
      # ------------------------------
      - name: Write sites.json
        run: |
          printf '%s\n' \
          '[' \
          '  "francetravail","indeed","hellowork","monster","jobijoba","meteojob","keljob","adzuna","alljobs","jora","jobted","linkedin","google_jobs","apec","cadremploi","wttj","lesjeudis","jobteaser","jobsthatsense","chooseyourboss","leboncoin","manpower","ouestjob"' \
          ']' > sites.json
          cat sites.json

      # ------------------------------
      # Fichier des filtres pour GPT
      # ------------------------------
      - name: Write filters.json
        run: |
          printf '%s\n' \
          '{' \
          '  "must_have_housing": true,' \
          '  "min_duration_days": 7,' \
          '  "max_duration_days": 92,' \
          '  "allow_only_metropole": true,' \
          '  "exclude_corse": true,' \
          '  "exclude_domcom": true,' \
          '  "allowed_jobs": [' \
          '    "serveur","serveuse","runner","aide de salle","aide barman","commis de bar",' \
          '    "vendangeur","porteuse","porteur","trieur","ouvrier agricole polyvalent",' \
          '    "ouvrier de cave","aide caviste","employe polyvalent","employé polyvalent",' \
          '    "cueilleur","cueilleuse"' \
          '  ]' \
          '}' > filters.json
          cat filters.json

      # ------------------------------
      # Script de collecte brute
      # ------------------------------
      - name: Write fetch_sites.py
        run: |
          printf '%s\n' \
          'import json, os, requests' \
          'from bs4 import BeautifulSoup' \
          '' \
          'SITES = json.load(open("sites.json","r",encoding="utf-8"))' \
          'TERMS = os.getenv("SEARCH_TERMS","").strip() or "${{ github.event.inputs.search_terms }}"' \
          '' \
          'def q(s): return requests.utils.quote(s)' \
          '' \
          '# Fonctions simples pour générer des URLs de recherche' \
          'def results_indeed(terms):' \
          '  return [{"source":"indeed","url":f"https://fr.indeed.com/jobs?q={q(terms)}+log%C3%A9&l=France","title":"Indeed search: "+terms}]' \
          '' \
          'def results_hellowork(terms):' \
          '  return [{"source":"hellowork","url":f"https://www.hellowork.com/fr-fr/emploi/recherche.html?k={q(terms)}+logement","title":"HelloWork search: "+terms}]' \
          '' \
          'def results_monster(terms):' \
          '  return [{"source":"monster","url":f"https://www.monster.fr/emploi/recherche/?q={q(terms)}&where=France","title":"Monster search: "+terms}]' \
          '' \
          'def results_francetravail(terms):' \
          '  return [{"source":"francetravail","url":f"https://candidat.francetravail.fr/offres/recherche?k={q(terms)}&l=France","title":"France Travail search: "+terms}]' \
          '' \
          'def results_simple(engine, terms):' \
          '  return [{"source":engine,"url":f"https://www.google.com/search?q=site%3A{engine}.com+{q(terms)}+log%C3%A9+France","title":engine+" via Google"}]' \
          '' \
          'DISPATCH = {' \
          '  "indeed": results_indeed,' \
          '  "hellowork": results_hellowork,' \
          '  "monster": results_monster,' \
          '  "francetravail": results_francetravail' \
          '}' \
          '' \
          'raw = []' \
          'terms_list = [t.strip() for t in TERMS.split(",") if t.strip()]' \
          'if not terms_list:' \
          '  terms_list = ["serveur logé","aide barman logé","runner logé","vendanges logé","ouvrier cave logé","aide caviste logé","employé polyvalent logé","cueilleur logé"]' \
          '' \
          'for site in SITES:' \
          '  for t in terms_list:' \
          '    fn = DISPATCH.get(site)' \
          '    if fn:' \
          '      raw.extend(fn(t))' \
          '    else:' \
          '      raw.extend(results_simple(site, t))' \
          '' \
          'json.dump(raw, open("offers_raw.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print(f"Collected seeds: {len(raw)}")' \
          > fetch_sites.py
          python fetch_sites.py

      # ------------------------------
      # GPT-5 mini : filtrage intelligent
      # ------------------------------
      - name: Write filter_with_gpt.py
        run: |
          printf '%s\n' \
          'import json, os' \
          'from openai import OpenAI' \
          '' \
          'client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))' \
          'model = os.getenv("OPENAI_MODEL","gpt-4o-mini")' \
          'temperature = float(os.getenv("OPENAI_TEMPERATURE","1"))' \
          '' \
          'offers = json.load(open("offers_raw.json","r",encoding="utf-8"))' \
          'filters = json.load(open("filters.json","r",encoding="utf-8"))' \
          '' \
          'prompt = {' \
          '  "role":"system",' \
          '  "content": "Tu es un assistant qui filtre des offres d\\u0027emploi. Ne supprime aucune offre. Classe et annote chaque entrée avec un score basé sur logement>lieu>durée>métier. Réponds en JSON."}' \
          '' \
          'resp = client.chat.completions.create(' \
          '  model=model,' \
          '  temperature=temperature,' \
          '  messages=[' \
          '    prompt,' \
          '    {"role":"user","content": json.dumps({"filters": filters, "offers": offers}, ensure_ascii=False)}' \
          '  ]' \
          ')' \
          '' \
          'content = resp.choices[0].message.content' \
          'try:' \
          '  data = json.loads(content)' \
          'except Exception:' \
          '  data = {"offers": offers, "raw_response": content}' \
          '' \
          'json.dump(data, open("offers_filtered.json","w",encoding="utf-8"), ensure_ascii=False, indent=2)' \
          'print("Filtered summary written.")' \
          > filter_with_gpt.py

      - name: Run filtering (GPT-5 mini)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python filter_with_gpt.py

      # ------------------------------
      # Génération et envoi du rapport
      # ------------------------------
      - name: Write email_report.py
        run: |
          printf '%s\n' \
          'import os, smtplib, json' \
          'from email.mime.multipart import MIMEMultipart' \
          'from email.mime.text import MIMEText' \
          '' \
          'RECIPIENT = os.getenv("RECIPIENT_EMAIL")' \
          'SENDER = os.getenv("SENDER_EMAIL")' \
          'SMTP_HOST = os.getenv("SMTP_HOST")' \
          'SMTP_PORT = int(os.getenv("SMTP_PORT"))' \
          'SMTP_USER = os.getenv("SMTP_USER")' \
          'SMTP_PASS = os.getenv("SMTP_PASS")' \
          '' \
          'data = json.load(open("offers_filtered.json","r",encoding="utf-8"))' \
          '' \
          'html = ["<h2>Offres saisonnières - Rapport</h2>","<ol>"]' \
          'items = data.get("offers", [])' \
          'for item in items[:200]:' \
          '  title = item.get("title","Offre")' \
          '  url = item.get("url","#")' \
          '  score = item.get("score","?")' \
          '  source = item.get("source","?")' \
          '  html.append(f"<li><b>{title}</b> - {source} - Score: {score} - <a href=\\"{url}\\">Lien</a></li>")' \
          'html.append("</ol>")' \
          '' \
          'msg = MIMEMultipart("alternative")' \
          'msg["Subject"] = "Veille offres saisonnières"' \
          'msg["From"] = SENDER' \
          'msg["To"] = RECIPIENT' \
          'msg.attach(MIMEText("\\n".join(html), "html", "utf-8"))' \
          '' \
          'with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as s:' \
          '  s.starttls()' \
          '  s.login(SMTP_USER, SMTP_PASS)' \
          '  s.sendmail(SENDER, RECIPIENT.split(","), msg.as_string())' \
          'print("Email sent to", RECIPIENT)' \
          > email_report.py

      - name: Send email
        env:
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENTS }}
          SENDER_EMAIL: ${{ secrets.SMTP_FROM }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
        run: python email_report.py

      # ------------------------------
      # Sauvegarde des fichiers générés
      # ------------------------------
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: job_offers
          path: |
            sites.json
            filters.json
            offers_raw.json
            offers_filtered.json